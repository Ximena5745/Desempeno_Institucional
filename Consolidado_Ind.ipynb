{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFlJDb5etvcZ33N9mjeP5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ximena5745/Desempeno_Institucional/blob/main/Consolidado_Ind.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6dPMghJ8Ign1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import ast\n",
        "import pandas as pd\n",
        "from html import unescape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Ximena5745/Desempeno_Institucional.git"
      ],
      "metadata": {
        "id": "yLXHriEzH2z8",
        "outputId": "39f46f33-0107-4e2a-ff30-948a19737cbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Desempeno_Institucional'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 23 (delta 5), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 1.19 MiB | 18.98 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/Desempeno_Institucional/Data\")"
      ],
      "metadata": {
        "id": "4-rTCGb2Kilp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Cargar todos los Excel del directorio, excluyendo cualquier archivo de consolidado previo\n",
        "archivos_excel = [f for f in (glob.glob(\"*.xlsx\") + glob.glob(\"*.xls\")) if \"consolidado\" not in f.lower()]\n"
      ],
      "metadata": {
        "id": "CCmPCuhrLCjN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "for archivo in archivos_excel:\n",
        "    try:\n",
        "        df_tmp = pd.read_excel(archivo)\n",
        "        df_tmp[\"Archivo\"] = archivo\n",
        "        dfs.append(df_tmp)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ No se pudo leer {archivo}: {e}\")\n",
        "\n",
        "if not dfs:\n",
        "    raise RuntimeError(\"No se encontraron archivos Excel para consolidar.\")\n",
        "\n",
        "# 4) Unir y estandarizar columnas (evitar autoreplicado y duplicados)\n",
        "df_todos = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
        "# Normalizar nombres de columnas a minúsculas para operar sin problemas de mayúsculas\n",
        "df_todos.columns = df_todos.columns.str.strip().str.lower()\n",
        "\n",
        "# 5) Limpieza pedida\n",
        "# 5.1 Eliminar columnas si existen\n",
        "cols_a_eliminar = [\"dependencia\", \"incidencia\", \"objectivos_relacionados\"]\n",
        "df_todos = df_todos.drop(columns=[c for c in cols_a_eliminar if c in df_todos.columns], errors=\"ignore\")\n",
        "\n",
        "# 5.2 Eliminar filas con 'fecha' vacía/nula\n",
        "if \"fecha\" in df_todos.columns:\n",
        "    df_todos = df_todos[df_todos[\"fecha\"].notna() & (df_todos[\"fecha\"].astype(str).str.strip() != \"\")]\n",
        "\n",
        "# 5.3 Corregir clasificacion \"Estrat&eacute;gico\" → \"Estratégico\" (y decodificar entidades HTML por si hay más)\n",
        "if \"clasificacion\" in df_todos.columns:\n",
        "    df_todos[\"clasificacion\"] = df_todos[\"clasificacion\"].astype(str).map(lambda s: unescape(s))\n",
        "    df_todos[\"clasificacion\"] = df_todos[\"clasificacion\"].replace({\"Estrat&eacute;gico\": \"Estratégico\"})\n",
        "\n",
        "# -------------------------\n",
        "# 6) EXPANSIÓN DE 'variables' CUANDO tipo == 'Serie Unica'\n",
        "#    Soporta dos formatos:\n",
        "#    a) Lista de diccionarios como string: \"[{'valor': 97.5, 'nombre': 'X', 'simbolo': 'Y'}, ...]\"\n",
        "#    b) Cadena con bloques {} consecutivos (fallback)\n",
        "# -------------------------\n",
        "\n",
        "def parse_variables_cell(x):\n",
        "    \"\"\"Devuelve una lista de dicts con llaves: valor, nombre, simbolo.\"\"\"\n",
        "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
        "        return []\n",
        "    if isinstance(x, list):\n",
        "        # Ya es lista de dicts\n",
        "        out = []\n",
        "        for item in x:\n",
        "            if isinstance(item, dict):\n",
        "                out.append({\n",
        "                    \"valor\": item.get(\"valor\"),\n",
        "                    \"nombre\": item.get(\"nombre\"),\n",
        "                    \"simbolo\": item.get(\"simbolo\")\n",
        "                })\n",
        "        return out\n",
        "\n",
        "    s = str(x).strip()\n",
        "    if s == \"\" or s.lower() in {\"nan\", \"none\", \"null\", \"[]\"}:\n",
        "        return []\n",
        "\n",
        "    # Intento 1: interpretar como literal de Python\n",
        "    try:\n",
        "        pyobj = ast.literal_eval(\n",
        "            s.replace(\"null\", \"None\").replace(\"true\", \"True\").replace(\"false\", \"False\")\n",
        "        )\n",
        "        if isinstance(pyobj, list):\n",
        "            out = []\n",
        "            for item in pyobj:\n",
        "                if isinstance(item, dict):\n",
        "                    out.append({\n",
        "                        \"valor\": item.get(\"valor\"),\n",
        "                        \"nombre\": item.get(\"nombre\"),\n",
        "                        \"simbolo\": item.get(\"simbolo\")\n",
        "                    })\n",
        "            return out\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Intento 2 (fallback): extraer bloques {...} y localizar campos\n",
        "    bloques = re.findall(r\"\\{[^{}]*\\}\", s)\n",
        "    out = []\n",
        "    for b in bloques:\n",
        "        # valor (acepta coma decimal)\n",
        "        m_val = re.search(r\"[\\'\\\"]?valor[\\'\\\"]?\\s*:\\s*([\\-+]?\\d+(?:[.,]\\d+)?)\", b, flags=re.IGNORECASE)\n",
        "        m_nom = re.search(r\"[\\'\\\"]?nombre[\\'\\\"]?\\s*:\\s*[\\'\\\"](.*?)[\\'\\\"]\", b, flags=re.IGNORECASE)\n",
        "        m_sim = re.search(r\"[\\'\\\"]?simbolo[\\'\\\"]?\\s*:\\s*[\\'\\\"](.*?)[\\'\\\"]\", b, flags=re.IGNORECASE)\n",
        "\n",
        "        valor = None\n",
        "        if m_val:\n",
        "            v = m_val.group(1).replace(\",\", \".\")\n",
        "            try:\n",
        "                valor = float(v)\n",
        "            except Exception:\n",
        "                valor = v  # déjalo como texto si no se puede convertir\n",
        "\n",
        "        nombre = m_nom.group(1) if m_nom else None\n",
        "        simbolo = m_sim.group(1) if m_sim else None\n",
        "\n",
        "        if any([m_val, m_nom, m_sim]):\n",
        "            out.append({\"valor\": valor, \"nombre\": nombre, \"simbolo\": simbolo})\n",
        "\n",
        "    return out\n",
        "\n",
        "# Aplicar solo a 'serie unica'\n",
        "if \"tipo\" in df_todos.columns and \"variables\" in df_todos.columns:\n",
        "    mask_serie = df_todos[\"tipo\"].astype(str).str.strip().str.lower() == \"serie unica\"\n",
        "    if mask_serie.any():\n",
        "        # Parsear lista de variables por fila\n",
        "        vars_list = df_todos.loc[mask_serie, \"variables\"].apply(parse_variables_cell)\n",
        "\n",
        "        # Número máximo de variables en cualquier fila Serie Unica\n",
        "        max_vars = int(vars_list.map(lambda lst: len(lst) if isinstance(lst, list) else 0).max())\n",
        "\n",
        "        # Crear columnas dinámicas\n",
        "        new_cols = []\n",
        "        for i in range(1, max_vars + 1):\n",
        "            for base in (\"Variable_Valor\", \"Variable_Nombre\", \"Variable_Simbolo\"):\n",
        "                col = f\"{base}_{i}\"\n",
        "                new_cols.append(col)\n",
        "                if col not in df_todos.columns:\n",
        "                    df_todos[col] = pd.NA\n",
        "\n",
        "        # Construir DataFrame expandido y asignar por índice\n",
        "        def expand_row(lst, max_n):\n",
        "            data = {}\n",
        "            if not isinstance(lst, list):\n",
        "                return pd.Series({c: pd.NA for c in new_cols})\n",
        "            for i in range(min(max_n, len(lst))):\n",
        "                item = lst[i] if isinstance(lst[i], dict) else {}\n",
        "                data[f\"Variable_Valor_{i+1}\"]  = item.get(\"valor\", pd.NA)\n",
        "                data[f\"Variable_Nombre_{i+1}\"] = item.get(\"nombre\", pd.NA)\n",
        "                data[f\"Variable_Simbolo_{i+1}\"]= item.get(\"simbolo\", pd.NA)\n",
        "            # Completar faltantes si la fila tiene menos variables que el máximo\n",
        "            for i in range(len(lst)+1, max_n+1):\n",
        "                data.setdefault(f\"Variable_Valor_{i}\", pd.NA)\n",
        "                data.setdefault(f\"Variable_Nombre_{i}\", pd.NA)\n",
        "                data.setdefault(f\"Variable_Simbolo_{i}\", pd.NA)\n",
        "            return pd.Series(data)\n",
        "\n",
        "        expanded = vars_list.apply(lambda lst: expand_row(lst, max_vars))\n",
        "        df_todos.loc[mask_serie, expanded.columns] = expanded.values\n",
        "\n",
        "# 7) Guardar resultado\n",
        "df_todos.to_excel(\"Consolidado.xlsx\", index=False)\n",
        "print(\"✅ Consolidado.xlsx generado con columnas de variables para 'Serie Unica' (si aplica).\")"
      ],
      "metadata": {
        "id": "zymHJ6hnutqS",
        "outputId": "13907d7c-a2db-46dd-e6b7-ad57ae984b4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Consolidado.xlsx generado con columnas de variables para 'Serie Unica' (si aplica).\n"
          ]
        }
      ]
    }
  ]
}